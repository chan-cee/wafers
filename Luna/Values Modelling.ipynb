{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('yk_values_dataframe.pkl', 'rb') as file:\n",
    "    yk_values = pickle.load(file)\n",
    "\n",
    "with open('ty_values_dataframe.pkl', 'rb') as file:\n",
    "    ty_values = pickle.load(file)\n",
    "\n",
    "with open('luna_values_dataframe.pkl', 'rb') as file:\n",
    "    luna_values = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YK:  (69579, 1025)\n",
      "TY:  (79785, 1402)\n",
      "Luna:  (10746, 3370)\n"
     ]
    }
   ],
   "source": [
    "print(\"YK: \", yk_values.shape)\n",
    "print(\"TY: \", ty_values.shape)\n",
    "print(\"Luna: \", luna_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5797, 79785)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.concat([yk_values, ty_values, luna_values], axis=1).T\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df.iloc[:, 2:] # each row represents a test with all its values\n",
    "df_values = df_values.reset_index().drop(columns='index')\n",
    "\n",
    "df_target = df.iloc[:, :2] # each row is test name and distribution\n",
    "df_target = df_target.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "def extract_qq_features(data, theoretical_distribution='norm'):\n",
    "    features = []\n",
    "    for index, row in data.iterrows():\n",
    "        #row = row.dropna()\n",
    "        row = pd.to_numeric(row, errors='coerce').dropna().values\n",
    "        if len(row) < 2:\n",
    "            features.append({\n",
    "                'Mean_Deviation': np.nan,\n",
    "                'Max_Deviation': np.nan,\n",
    "                'Std_Deviation': np.nan,\n",
    "                'Mean_Abs_Deviation': np.nan,\n",
    "                'Median_Abs_Deviation': np.nan,\n",
    "                'Q1_Deviation': np.nan,\n",
    "                'Q5_Deviation': np.nan,\n",
    "                'Q25_Deviation': np.nan,\n",
    "                'Q50_Deviation': np.nan,\n",
    "                'Q75_Deviation': np.nan,\n",
    "                'Q95_Deviation': np.nan,\n",
    "                'Q99_Deviation': np.nan,\n",
    "                'AD_Stat': np.nan,\n",
    "                'Line_Fit_R_Squared': np.nan,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        qq_plot = stats.probplot(row, dist=theoretical_distribution, plot=None)\n",
    "        quantiles_theoretical = qq_plot[0][0]  # Theoretical quantiles\n",
    "        quantiles_empirical = qq_plot[0][1]    # Empirical quantiles\n",
    "        deviations = np.array(quantiles_empirical) - np.array(quantiles_theoretical)\n",
    "        mean_abs_deviation = np.mean(np.abs(deviations))\n",
    "        median_abs_deviation = np.median(np.abs(deviations))\n",
    "        ad_stat = stats.anderson(row, dist=theoretical_distribution).statistic\n",
    "        coeffs = np.polyfit(quantiles_theoretical, quantiles_empirical, 1)\n",
    "        line_fit_r_squared = np.corrcoef(quantiles_theoretical, quantiles_empirical)[0, 1]**2\n",
    "\n",
    "        features.append({\n",
    "            'Mean_Deviation': np.mean(deviations),\n",
    "            'Max_Deviation': np.max(deviations),\n",
    "            'Std_Deviation': np.std(deviations),\n",
    "            'Mean_Abs_Deviation': mean_abs_deviation,\n",
    "            'Median_Abs_Deviation': median_abs_deviation,\n",
    "            'Q1_Deviation': np.abs(np.percentile(row, 1) - np.percentile(quantiles_theoretical, 1)),\n",
    "            'Q5_Deviation': np.abs(np.percentile(row, 5) - np.percentile(quantiles_theoretical, 5)),\n",
    "            'Q25_Deviation': np.abs(np.percentile(row, 25) - np.percentile(quantiles_theoretical, 25)),\n",
    "            'Q50_Deviation': np.abs(np.percentile(row, 50) - np.percentile(quantiles_theoretical, 50)),\n",
    "            'Q75_Deviation': np.abs(np.percentile(row, 75) - np.percentile(quantiles_theoretical, 75)),\n",
    "            'Q95_Deviation': np.abs(np.percentile(row, 95) - np.percentile(quantiles_theoretical, 95)),\n",
    "            'Q99_Deviation': np.abs(np.percentile(row, 99) - np.percentile(quantiles_theoretical, 99)),\n",
    "            'AD_Stat': ad_stat,\n",
    "            'Line_Fit_R_Squared': line_fit_r_squared\n",
    "        })\n",
    "    return pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = extract_qq_features(df_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Deviation</th>\n",
       "      <th>Max_Deviation</th>\n",
       "      <th>Std_Deviation</th>\n",
       "      <th>Q1_Deviation</th>\n",
       "      <th>Q5_Deviation</th>\n",
       "      <th>Q25_Deviation</th>\n",
       "      <th>Q50_Deviation</th>\n",
       "      <th>Q75_Deviation</th>\n",
       "      <th>Q95_Deviation</th>\n",
       "      <th>Q99_Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>29.265735</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>27.325987</td>\n",
       "      <td>26.644768</td>\n",
       "      <td>25.674474</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.325526</td>\n",
       "      <td>23.355232</td>\n",
       "      <td>22.674013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.611945e+04</td>\n",
       "      <td>26674.230146</td>\n",
       "      <td>1142.707783</td>\n",
       "      <td>9944.325987</td>\n",
       "      <td>15406.644768</td>\n",
       "      <td>15980.674474</td>\n",
       "      <td>16408.0</td>\n",
       "      <td>16486.325526</td>\n",
       "      <td>16820.355232</td>\n",
       "      <td>16902.674013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.088813e+03</td>\n",
       "      <td>19460.734265</td>\n",
       "      <td>4963.807017</td>\n",
       "      <td>49.325987</td>\n",
       "      <td>259.644768</td>\n",
       "      <td>2865.674474</td>\n",
       "      <td>6448.0</td>\n",
       "      <td>10795.325526</td>\n",
       "      <td>15984.555232</td>\n",
       "      <td>18766.914013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.174731</td>\n",
       "      <td>0.997022</td>\n",
       "      <td>1.300306</td>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.326671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.673329</td>\n",
       "      <td>2.638456</td>\n",
       "      <td>3.300306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.500000e-01</td>\n",
       "      <td>-0.001851</td>\n",
       "      <td>0.478511</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>0.107895</td>\n",
       "      <td>0.532069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.217931</td>\n",
       "      <td>1.042105</td>\n",
       "      <td>1.006940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>1.010798e+00</td>\n",
       "      <td>11.171712</td>\n",
       "      <td>0.998744</td>\n",
       "      <td>3.324022</td>\n",
       "      <td>2.644300</td>\n",
       "      <td>1.674390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.325610</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>1.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>-2.539779e-16</td>\n",
       "      <td>3.828288</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>2.324022</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>0.674390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674390</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>2.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>-2.539779e-16</td>\n",
       "      <td>3.828288</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>2.324022</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>0.674390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674390</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>2.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>1.000372e+00</td>\n",
       "      <td>4.828288</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>3.324022</td>\n",
       "      <td>2.644300</td>\n",
       "      <td>1.674390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.325610</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>1.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>-2.539779e-16</td>\n",
       "      <td>3.828288</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>2.324022</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>0.674390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674390</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>2.324022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5797 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mean_Deviation  Max_Deviation  Std_Deviation  Q1_Deviation  \\\n",
       "0       2.500000e+01      29.265735       0.999939     27.325987   \n",
       "1       1.611945e+04   26674.230146    1142.707783   9944.325987   \n",
       "2       7.088813e+03   19460.734265    4963.807017     49.325987   \n",
       "3      -1.000000e+00       2.174731       0.997022      1.300306   \n",
       "4      -7.500000e-01      -0.001851       0.478511      0.023060   \n",
       "...              ...            ...            ...           ...   \n",
       "5792    1.010798e+00      11.171712       0.998744      3.324022   \n",
       "5793   -2.539779e-16       3.828288       0.999665      2.324022   \n",
       "5794   -2.539779e-16       3.828288       0.999665      2.324022   \n",
       "5795    1.000372e+00       4.828288       0.998571      3.324022   \n",
       "5796   -2.539779e-16       3.828288       0.999665      2.324022   \n",
       "\n",
       "      Q5_Deviation  Q25_Deviation  Q50_Deviation  Q75_Deviation  \\\n",
       "0        26.644768      25.674474           25.0      24.325526   \n",
       "1     15406.644768   15980.674474        16408.0   16486.325526   \n",
       "2       259.644768    2865.674474         6448.0   10795.325526   \n",
       "3         0.638456       0.326671            1.0       1.673329   \n",
       "4         0.107895       0.532069            1.0       1.217931   \n",
       "...            ...            ...            ...            ...   \n",
       "5792      2.644300       1.674390            1.0       0.325610   \n",
       "5793      1.644300       0.674390            0.0       0.674390   \n",
       "5794      1.644300       0.674390            0.0       0.674390   \n",
       "5795      2.644300       1.674390            1.0       0.325610   \n",
       "5796      1.644300       0.674390            0.0       0.674390   \n",
       "\n",
       "      Q95_Deviation  Q99_Deviation  \n",
       "0         23.355232      22.674013  \n",
       "1      16820.355232   16902.674013  \n",
       "2      15984.555232   18766.914013  \n",
       "3          2.638456       3.300306  \n",
       "4          1.042105       1.006940  \n",
       "...             ...            ...  \n",
       "5792       0.644300       1.324022  \n",
       "5793       1.644300       2.324022  \n",
       "5794       1.644300       2.324022  \n",
       "5795       0.644300       1.324022  \n",
       "5796       1.644300       2.324022  \n",
       "\n",
       "[5797 rows x 10 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = features_df.isnull().any(axis=1)\n",
    "df_target = df_target[~mask] # drop corresponding test target with null features\n",
    "\n",
    "features_df.dropna(inplace=True) # drop test with null features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns_to_drop = ['Target', 'Name', 'Distribution Type', 'Target_Encoded']\n",
    "X = features_df\n",
    "y = df_target['Distribution Type'].apply(lambda x: 1 if x in ['outlier', 'longtail'] else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4148\n",
       "1    1646\n",
       "Name: Distribution Type, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       827\n",
      "           1       0.92      0.89      0.91       332\n",
      "\n",
      "    accuracy                           0.95      1159\n",
      "   macro avg       0.94      0.93      0.93      1159\n",
      "weighted avg       0.95      0.95      0.95      1159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9499568593615185\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       827\n",
      "           1       0.91      0.91      0.91       332\n",
      "\n",
      "    accuracy                           0.95      1159\n",
      "   macro avg       0.94      0.94      0.94      1159\n",
      "weighted avg       0.95      0.95      0.95      1159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_smote = RandomForestClassifier()\n",
    "\n",
    "model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_smote = model_smote.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "importances = model_smote.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_smote.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fd2bc93e893ca47673c143fe9bb91339f419204f0f0ce83affb1375d7b0d3ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
