{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94729cf",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716ef75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da8049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x000002B52FCC60B0>\n"
     ]
    }
   ],
   "source": [
    "#Loading the cleaned, concatenated using the npz file \n",
    "loaded_data = np.load('YK_TY_df.npz')\n",
    "print(loaded_data)\n",
    "loaded_data_arrays = loaded_data['data']\n",
    "loaded_labels = loaded_data['labels']\n",
    "loaded_df = pd.DataFrame({'Data': loaded_data_arrays.tolist(), 'Distribution Type': loaded_labels.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a0e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data Distribution Type\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        functional\n",
      "1  [0.399193055385744, 0.3974405999103395, 0.3969...          longtail\n",
      "2  [0.0, 0.0002055076037813, 0.000308261405672, 0...          longtail\n",
      "3  [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...        functional\n",
      "4  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...        functional\n",
      "functional    1186\n",
      "outlier        373\n",
      "normal         327\n",
      "longtail       290\n",
      "bimodal        131\n",
      "discrete       120\n",
      "Name: Distribution Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Visualing the data we have imported\n",
    "print(loaded_df.head())\n",
    "print(loaded_df['Distribution Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking shape \n",
    "print(len(loaded_df['Data'].iloc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689fbce",
   "metadata": {},
   "source": [
    "As seen above, the classes are unbalanced. It is not possible to oversample the classes with fewer numbers (eg discrete, bimodal etc) as it might introduce bias if we input 50,000 data points each for instance we oversample. Hence, we will try to balance the class by limiting each class to ~100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c028e96",
   "metadata": {},
   "source": [
    "## Addressing the unbalanced classes\n",
    "We shall cut each class to 100 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a62f51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: bimodal\n",
      "                                                 Data Distribution Type\n",
      "21  [0.5733333333333334, 0.3333333333333333, 0.52,...           bimodal\n",
      "22  [0.5441176470588236, 0.5, 0.6323529411764706, ...           bimodal\n",
      "23  [0.5789473684210528, 0.3157894736842106, 0.543...           bimodal\n",
      "32  [0.4029850746268657, 0.373134328358209, 0.6567...           bimodal\n",
      "69  [0.4519230769230768, 0.3846153846153846, 0.423...           bimodal\n",
      "------\n",
      "Group: discrete\n",
      "                                                  Data Distribution Type\n",
      "97   [0.526276733389146, 0.4399402542050392, 0.5414...          discrete\n",
      "102  [0.5361310054553652, 0.4429104227188603, 0.547...          discrete\n",
      "118  [0.3999999999999999, 0.3999999999999999, 0.399...          discrete\n",
      "119  [0.25, 0.5, 0.25, 0.25, 0.3333333333333335, 0....          discrete\n",
      "147  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          discrete\n",
      "------\n",
      "Group: functional\n",
      "                                                Data Distribution Type\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        functional\n",
      "3  [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...        functional\n",
      "4  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...        functional\n",
      "5  [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...        functional\n",
      "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        functional\n",
      "------\n",
      "Group: longtail\n",
      "                                                 Data Distribution Type\n",
      "1   [0.399193055385744, 0.3974405999103395, 0.3969...          longtail\n",
      "2   [0.0, 0.0002055076037813, 0.000308261405672, 0...          longtail\n",
      "84  [0.3804993788936786, 0.3871456870753418, 0.428...          longtail\n",
      "85  [0.3863331261653204, 0.439285270354258, 0.4686...          longtail\n",
      "86  [0.7492980162046248, 0.7903511002021304, 0.730...          longtail\n",
      "------\n",
      "Group: normal\n",
      "                                                 Data Distribution Type\n",
      "12  [0.6206896551724138, 0.3448275862068966, 0.448...            normal\n",
      "13  [0.4118502362777168, 0.1072337331879307, 0.450...            normal\n",
      "14  [0.4363636363636363, 0.6909090909090909, 0.490...            normal\n",
      "15  [0.2121212121212121, 0.2727272727272727, 0.651...            normal\n",
      "16  [0.4642857142857143, 0.4285714285714286, 0.642...            normal\n",
      "------\n",
      "Group: outlier\n",
      "                                                  Data Distribution Type\n",
      "113  [0.0267857142857142, 0.0267857142857142, 0.017...           outlier\n",
      "114  [0.1531531531531531, 0.1621621621621621, 0.153...           outlier\n",
      "115  [0.2736842105263158, 0.2842105263157894, 0.273...           outlier\n",
      "120  [0.5833333333333335, 0.625, 0.5833333333333335...           outlier\n",
      "121  [0.1999999999999999, 0.28, 0.1999999999999999,...           outlier\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "#Grouping the dataframe by the distribution type\n",
    "grouped_df = loaded_df.groupby('Distribution Type')\n",
    "#Verifying that grouping is indeed done\n",
    "for group_name, group_data in grouped_df:\n",
    "    print(\"Group: {}\".format(group_name))\n",
    "    print(group_data.head())\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b03b573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to trim the group\n",
    "def trim_df (new_df,grouped_df):\n",
    "    for _,group in grouped_df:\n",
    "        count = len(group)\n",
    "        #If the number of instance for any group is below limit (100), print warning statement\n",
    "        if count <= 100:\n",
    "            print(\"Group: {} has less than 100!\".format(group))\n",
    "        else:\n",
    "            trimmed_group = group.sample(n=100,random_state=42)\n",
    "        trimmed_df = pd.concat([new_df,trimmed_group])\n",
    "        new_df = trimmed_df\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a43b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Data, Distribution Type]\n",
      "Index: []\n",
      "                                                  Data Distribution Type\n",
      "0    [0.7591974135354557, 0.1181593030329548, 0.193...           bimodal\n",
      "1    [0.7519267102526808, 0.2311100841364126, 0.316...           bimodal\n",
      "2    [0.6567157154958743, 0.6949298779531272, 0.253...           bimodal\n",
      "3    [0.6688971655829814, 0.6919859857332238, 0.257...           bimodal\n",
      "4    [1.2104049194514532e-24, 1.202252104985288e-24...           bimodal\n",
      "..                                                 ...               ...\n",
      "595  [0.128440366972477, 0.128440366972477, 0.13761...           outlier\n",
      "596  [0.7654995657651831, 0.7636762084978036, 0.757...           outlier\n",
      "597  [0.6666455123336696, 0.7699331037568015, 0.790...           outlier\n",
      "598  [0.74529091888708, 0.7469155875998774, 0.73799...           outlier\n",
      "599  [0.992110753094851, 0.9927640028385896, 0.9931...           outlier\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "bimodal       100\n",
      "discrete      100\n",
      "functional    100\n",
      "longtail      100\n",
      "normal        100\n",
      "outlier       100\n",
      "Name: Distribution Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Creating a new dataframe to store the trimmed data\n",
    "trimmed_df = pd.DataFrame(columns=loaded_df.columns)\n",
    "print(trimmed_df.head())\n",
    "#Applying the function\n",
    "trimmed_df = trim_df(trimmed_df,grouped_df)\n",
    "#Resetting the index of the trimmed dataframe\n",
    "trimmed_df = trimmed_df.reset_index(drop=True)\n",
    "print(trimmed_df)\n",
    "print(trimmed_df['Distribution Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a27f3",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "We will start modelling LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eade4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant modules to build model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8db06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating the model we will be using\n",
    "num_classes = 6\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(50000, 1)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40eba8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the data beforehand before modelling\n",
    "def sort_df(df):\n",
    "    #Make a copy then sort\n",
    "    sorted_df = df\n",
    "    for index in range(sorted_df.shape[0]):\n",
    "        sorted_df['Data'].iloc[index].sort()\n",
    "    return sorted_df\n",
    "#Function to convert all the data (individual tuple) into arrays/list for modelling\n",
    "def convert_data_rows(df):\n",
    "    data_points = []\n",
    "    for colName,colData in df.items():\n",
    "        data_points.append(np.asarray(colData))\n",
    "    return data_points\n",
    "#Prepare the training and sorting data \n",
    "def train_test(model_df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    xData = sort_df(model_df)['Data']\n",
    "    yData = sort_df(model_df)['Distribution Type']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xData,yData,test_size = 0.2,random_state=42)\n",
    "    X_train = convert_data_rows(X_train)\n",
    "    X_test = convert_data_rows(X_test)\n",
    "    X_train = np.array(X_train).astype('float64')\n",
    "    X_test= np.array(X_test).astype('float64')\n",
    "    num_samples, num_timesteps = X_train.shape\n",
    "    X_train = X_train.reshape(num_samples,num_timesteps,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],num_timesteps,1)\n",
    "    Y_train = label_encoder.fit_transform(Y_train)\n",
    "    Y_train = to_categorical(Y_train,num_classes)\n",
    "    Y_test = label_encoder.fit_transform(Y_test)\n",
    "    Y_test = to_categorical(Y_test,num_classes)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43eeec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing training data \n",
    "X_train,X_test,Y_train,Y_test = train_test(trimmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e137454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 50000, 1)\n",
      "(120, 50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505fecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 1785s 125s/step - loss: 1.7877 - accuracy: 0.1813\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 3829s 261s/step - loss: 1.7776 - accuracy: 0.2333\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 4988s 334s/step - loss: 1.7709 - accuracy: 0.2042\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 5622s 375s/step - loss: 1.7479 - accuracy: 0.2438\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 6053s 404s/step - loss: 1.7259 - accuracy: 0.2250\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 6259s 418s/step - loss: 1.7106 - accuracy: 0.2188\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 6510s 435s/step - loss: 1.7078 - accuracy: 0.2417\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 6751s 446s/step - loss: 1.7016 - accuracy: 0.2458\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 6354s 422s/step - loss: 1.6963 - accuracy: 0.2583\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 6375s 425s/step - loss: 1.6929 - accuracy: 0.2167\n",
      "Time taken: 54526.24233055115\n"
     ]
    }
   ],
   "source": [
    "#Running the model\n",
    "import time\n",
    "start_time = time.time()\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)\n",
    "end_time = time.time()\n",
    "elasped_time = end_time - start_time\n",
    "print(\"Time taken: {}\".format(elasped_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41e2de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model, load_model\n",
    "save_model(model,'LSTM_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a939c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try load model\n",
    "loaded_model_LSTM = load_model('LSTM_trained.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4b258",
   "metadata": {},
   "source": [
    "## Attempting another model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87de9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use same x train y train except further split the train into validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)  # 60% train, 20% validation, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a5cff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "modelCnn = Sequential()\n",
    "modelCnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "modelCnn.add(MaxPooling1D(pool_size=2))\n",
    "modelCnn.add(Flatten())\n",
    "modelCnn.add(Dense(64, activation='relu'))\n",
    "modelCnn.add(Dense(num_classes, activation='softmax'))\n",
    "modelCnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbd89915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 20s 2s/step - loss: 48.1930 - accuracy: 0.1444 - val_loss: 27.0156 - val_accuracy: 0.2250\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 10.3682 - accuracy: 0.2722 - val_loss: 9.1428 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 6.7085 - accuracy: 0.2667 - val_loss: 5.9133 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 3.5920 - accuracy: 0.3222 - val_loss: 2.2561 - val_accuracy: 0.3750\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2.8483 - accuracy: 0.3583 - val_loss: 2.7107 - val_accuracy: 0.2917\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2.2301 - accuracy: 0.3778 - val_loss: 3.1953 - val_accuracy: 0.3167\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2.8035 - accuracy: 0.3333 - val_loss: 3.2861 - val_accuracy: 0.2833\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 3.2594 - accuracy: 0.3306 - val_loss: 2.2498 - val_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2.9189 - accuracy: 0.3417 - val_loss: 3.5302 - val_accuracy: 0.2833\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2.2838 - accuracy: 0.3833 - val_loss: 2.5058 - val_accuracy: 0.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0020c5510>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "modelCnn.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90e6f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "save_model = save_model(modelCnn,'Cnn_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b312e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the CNN model and try it with test\n",
    "cnn_model = load_model('Cnn_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ea3f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 283ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bb3d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 1 1 1 1 1 4 3 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 4 5 1 0 1 1 4 4\n",
      " 1 4 1 1 1 5 1 5 1 4 1 0 4 1 1 1 1 1 0 1 1 1 1 1 4 4 1 1 1 5 1 1 1 1 1 1 4\n",
      " 2 1 3 1 5 1 1 4 1 1 3 0 1 2 4 1 1 5 0 4 1 1 1 0 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 1 1 1 1 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes_cnn = np.argmax(y_pred_cnn,axis=1)\n",
    "print(y_pred_classes_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c33e9be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 89s 10s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_lstm = loaded_model_LSTM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04373595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 4 2 2 5 2 4 4 4 4 4 4 4 4 4 4 2 4 2 4 4 4 4 4 4 2 4 2 4 4 5 4 5 4 4 4\n",
      " 4 4 4 4 4 2 4 2 4 4 2 4 4 2 2 2 1 4 4 4 4 4 4 4 4 4 4 5 4 4 4 2 4 4 4 4 4\n",
      " 4 4 4 4 2 4 1 4 4 4 4 4 4 4 4 4 5 2 4 4 2 4 2 4 4 4 4 4 4 4 5 2 2 4 4 5 4\n",
      " 2 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes_lstm = np.argmax(y_pred_lstm,axis=1)\n",
    "print(y_pred_classes_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c40669",
   "metadata": {},
   "source": [
    "#Check the actual labels/ Y test\n",
    "Y_test_check = np.argmax(Y_test,axis=1)\n",
    "print(Y_test_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dba12bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.325\n"
     ]
    }
   ],
   "source": [
    "#Accuracy for CNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(Y_test_check,y_pred_classes_cnn)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f697cb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Accuracy for LSTM\n",
    "accuracy = accuracy_score(Y_test_check,y_pred_classes_lstm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ccf84b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d07e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nxg00371\\appdata\\local\\anaconda3\\lib\\site-packages (1.7.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\nxg00371\\appdata\\local\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nxg00371\\appdata\\local\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "177609cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'objective': 'multi:softmax',  # Multi-class classification objective\n",
    "'num_class': 6,  # Number of classes\n",
    "'eta': 0.3,  # Learning rate\n",
    "'max_depth': 6,  # Maximum depth of the trees\n",
    "'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n",
    "'seed': 42  # Random seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4aef3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training and sorting data \n",
    "def train_test_XGB(model_df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    xData = sort_df(model_df)['Data']\n",
    "    yData = sort_df(model_df)['Distribution Type']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xData,yData,test_size = 0.2,random_state=42) \n",
    "    X_train = convert_data_rows(X_train)\n",
    "    X_test = convert_data_rows(X_test)\n",
    "    X_train = np.array(X_train).astype('float64')\n",
    "    X_test= np.array(X_test).astype('float64')\n",
    "    #num_samples, num_timesteps = X_train.shape\n",
    "    #X_train = X_train.reshape(num_samples,num_timesteps,1)\n",
    "    #X_test = X_test.reshape(X_test.shape[0],num_timesteps,1)\n",
    "    Y_train = label_encoder.fit_transform(Y_train)\n",
    "    Y_train = to_categorical(Y_train,num_classes)\n",
    "    Y_test = label_encoder.fit_transform(Y_test)\n",
    "    Y_test = to_categorical(Y_test,num_classes)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe254350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training, validation and test data sets\n",
    "X_train_XGB, X_test_XGB, Y_train_XGB, Y_test_XGB = train_test_XGB(trimmed_df)\n",
    "#X_train_XGB, X_val_XGB, Y_train_XGB, Y_val_XGB = train_test_split(X_train_XGB, Y_train_XGB, test_size=0.25, random_state=42)  # 70% train, 15% validation, 15% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d17ca4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 6)\n",
      "(120, 6)\n",
      "(480,)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "#Ensure shape of the y is correst\n",
    "print(Y_train_XGB.shape)\n",
    "print(Y_test_XGB.shape)\n",
    "Y_train_XGB = np.argmax(Y_train_XGB,axis=1)\n",
    "Y_test_XGB = np.argmax(Y_test_XGB,axis=1)\n",
    "print(Y_train_XGB.shape)\n",
    "print(Y_test_XGB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42b7cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 50000)\n"
     ]
    }
   ],
   "source": [
    "#Check shape of x \n",
    "print(X_train_XGB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f7540a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_XGB, label=Y_train_XGB)\n",
    "dtest = xgb.DMatrix(X_test_XGB, label=Y_test_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa0ac688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGB = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c40f0e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(X_train_XGB,Y_train_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d84c47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = xgb_classifier.predict(X_test_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3fbdffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 3 0 1 2 0 3 0 3 0 1 1 5 0 2 0 1 2 0 0 5 5 5 3 5 0 1 0 4 0 1 0 2 2 4 1\n",
      " 5 4 2 3 0 5 5 0 1 4 1 0 4 1 2 1 5 5 3 2 1 1 1 0 1 0 5 5 0 5 3 0 3 0 0 4 3\n",
      " 5 5 3 2 5 3 2 4 5 3 1 0 1 2 3 2 2 5 0 4 1 2 1 0 5 0 4 2 5 3 0 0 1 2 2 0 1\n",
      " 1 3 5 3 3 3 2 0 0]\n",
      "accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "print(pred_classes)\n",
    "accuracy = accuracy_score(pred_classes,Y_test_XGB)\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cce80625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_filename = \"XGB_model_try.pkl\"\n",
    "with open(model_filename,'wb') as model_file_2:\n",
    "    pickle.dump(xgb_classifier,model_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f033bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 5 0 1 2 0 4 0 3 0 1 1 5 3 2 0 2 1 0 0 5 5 5 3 5 0 1 5 4 5 1 0 2 1 4 1\n",
      " 5 4 2 3 0 5 5 0 1 4 1 0 4 2 2 1 5 5 3 2 1 1 1 0 1 3 5 5 0 5 5 0 3 3 0 4 3\n",
      " 4 5 3 2 5 4 2 4 5 3 0 0 1 2 3 2 2 5 0 3 2 2 2 0 4 0 0 2 5 3 0 4 1 2 2 4 1\n",
      " 4 5 5 3 3 3 1 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da45d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nxg00371\\AppData\\Local\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After tuning hyperparameters\n",
    "xgb_classifier_tuned = xgb.XGBClassifier({'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200})\n",
    "xgb_classifier_tuned.fit(X_train_XGB,Y_train_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "daf316f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 3 0 1 2 0 3 0 3 0 1 1 5 0 2 0 1 2 0 0 5 5 5 3 5 0 1 0 4 0 1 0 2 2 4 1\n",
      " 5 4 2 3 0 5 5 0 1 4 1 0 4 1 2 1 5 5 3 2 1 1 1 0 1 0 5 5 0 5 3 0 3 0 0 4 3\n",
      " 5 5 3 2 5 3 2 4 5 3 1 0 1 2 3 2 2 5 0 4 1 2 1 0 5 0 4 2 5 3 0 0 1 2 2 0 1\n",
      " 1 3 5 3 3 3 2 0 0]\n",
      "accuracy:  0.775\n"
     ]
    }
   ],
   "source": [
    "pred_classes = xgb_classifier_tuned.predict(X_test_XGB)\n",
    "print(pred_classes)\n",
    "accuracy = accuracy_score(pred_classes,Y_test_XGB)\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "420e9946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00\n"
     ]
    }
   ],
   "source": [
    "#Findng out inference time \n",
    "import time\n",
    "start_time = time.time()\n",
    "y_pred_XGB = model_XGB.predict(dtest)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time taken: {:.2f}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b61d8e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 5., 0., 1., 2., 0., 3., 0., 3., 0., 1., 1., 5., 0., 2., 0.,\n",
       "       1., 2., 0., 0., 5., 5., 5., 3., 5., 0., 1., 0., 4., 1., 1., 0., 2.,\n",
       "       2., 4., 1., 5., 4., 2., 3., 0., 5., 0., 0., 1., 4., 1., 0., 4., 1.,\n",
       "       1., 1., 5., 5., 3., 2., 1., 1., 1., 0., 1., 0., 5., 1., 0., 5., 3.,\n",
       "       0., 3., 0., 0., 4., 3., 5., 5., 3., 2., 5., 3., 2., 4., 5., 3., 1.,\n",
       "       0., 1., 2., 3., 2., 2., 5., 0., 4., 1., 2., 1., 0., 5., 0., 4., 2.,\n",
       "       5., 3., 0., 0., 1., 2., 2., 0., 1., 1., 3., 5., 3., 3., 3., 2., 0.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94e7d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7583333333333333\n"
     ]
    }
   ],
   "source": [
    "pred_test = model_XGB.predict(dtest)\n",
    "accuracy_test = accuracy_score(Y_test_XGB, pred_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1f345",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters of XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3345ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_XGB = xgb.XGBClassifier()\n",
    "param_grid = {\n",
    "'n_estimators': [100, 200, 300],\n",
    "'max_depth': [3, 4, 5],\n",
    "'learning_rate': [0.1, 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c28928ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=3,\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rat...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    factor=2, n_jobs=-1,\n",
       "                    param_grid={&#x27;learning_rate&#x27;: [0.1, 0.01, 0.001],\n",
       "                                &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                                &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                    random_state=42, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=3,\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rat...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    factor=2, n_jobs=-1,\n",
       "                    param_grid={&#x27;learning_rate&#x27;: [0.1, 0.01, 0.001],\n",
       "                                &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                                &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                    random_state=42, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=3,\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rat...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    factor=2, n_jobs=-1,\n",
       "                    param_grid={'learning_rate': [0.1, 0.01, 0.001],\n",
       "                                'max_depth': [3, 4, 5],\n",
       "                                'n_estimators': [100, 200, 300]},\n",
       "                    random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = HalvingGridSearchCV(classifier_XGB, param_grid, scoring='accuracy', cv=3, factor=2, random_state=42,n_jobs=-1)\n",
    "search.fit(X_train_XGB, Y_train_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d06e7591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best Accuracy:  0.6597222222222223\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", search.best_params_)\n",
    "print(\"Best Accuracy: \", search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1de32aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "best_model = search.best_estimator_\n",
    "pred_test = best_model.predict(X_test_XGB)\n",
    "accuracy_test = accuracy_score(Y_test_XGB, pred_test)\n",
    "print(\"Test Accuracy: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907bf09",
   "metadata": {},
   "source": [
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00529beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_filename = \"xgb_model.pkl\"\n",
    "with open(model_filename,'wb') as model_file:\n",
    "    pickle.dump(best_model,model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca2b0a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "719bb290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\nxg00371\\Desktop\\Coding Projs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\",os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e306e",
   "metadata": {},
   "source": [
    "## Support vector machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82f3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training and sorting data \n",
    "def support_vector(model_df):\n",
    "    #label_encoder = LabelEncoder()\n",
    "    xData = sort_df(model_df)['Data']\n",
    "    yData = sort_df(model_df)['Distribution Type']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xData,yData,test_size = 0.2,random_state=42) \n",
    "    X_train = convert_data_rows(X_train)\n",
    "    X_test = convert_data_rows(X_test)\n",
    "    X_train = np.array(X_train).astype('float64')\n",
    "    X_test= np.array(X_test).astype('float64')\n",
    "    #num_samples, num_timesteps = X_train.shape\n",
    "    #X_train = X_train.reshape(num_samples,num_timesteps,1)\n",
    "    #X_test = X_test.reshape(X_test.shape[0],num_timesteps,1)\n",
    "    #Y_train = label_encoder.fit_transform(Y_train)\n",
    "    #Y_train = to_categorical(Y_train,num_classes)\n",
    "    #Y_test = label_encoder.fit_transform(Y_test)\n",
    "    #Y_test = to_categorical(Y_test,num_classes)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d001f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Data Distribution Type\n",
      "0    [0.7591974135354557, 0.1181593030329548, 0.193...           bimodal\n",
      "1    [0.7519267102526808, 0.2311100841364126, 0.316...           bimodal\n",
      "2    [0.6567157154958743, 0.6949298779531272, 0.253...           bimodal\n",
      "3    [0.6688971655829814, 0.6919859857332238, 0.257...           bimodal\n",
      "4    [1.2104049194514532e-24, 1.202252104985288e-24...           bimodal\n",
      "..                                                 ...               ...\n",
      "595  [0.128440366972477, 0.128440366972477, 0.13761...           outlier\n",
      "596  [0.7654995657651831, 0.7636762084978036, 0.757...           outlier\n",
      "597  [0.6666455123336696, 0.7699331037568015, 0.790...           outlier\n",
      "598  [0.74529091888708, 0.7469155875998774, 0.73799...           outlier\n",
      "599  [0.992110753094851, 0.9927640028385896, 0.9931...           outlier\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "bimodal       100\n",
      "discrete      100\n",
      "functional    100\n",
      "longtail      100\n",
      "normal        100\n",
      "outlier       100\n",
      "Name: Distribution Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trimmed_df)\n",
    "print(trimmed_df['Distribution Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d48a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SV, X_test_SV, Y_train_SV, Y_test_SV = support_vector(trimmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60811433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a75aa4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "svm_classifier = SVC(kernel='linear',random_state=42)\n",
    "svm_classifier.fit(X_train_SV,Y_train_SV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "97796e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['discrete', 'normal', 'outlier', 'bimodal', 'discrete',\n",
       "       'functional', 'bimodal', 'normal', 'bimodal', 'longtail',\n",
       "       'bimodal', 'discrete', 'discrete', 'outlier', 'bimodal',\n",
       "       'functional', 'bimodal', 'discrete', 'bimodal', 'bimodal',\n",
       "       'bimodal', 'outlier', 'outlier', 'outlier', 'normal', 'outlier',\n",
       "       'bimodal', 'longtail', 'bimodal', 'normal', 'outlier', 'discrete',\n",
       "       'bimodal', 'functional', 'longtail', 'normal', 'outlier',\n",
       "       'outlier', 'normal', 'functional', 'longtail', 'bimodal',\n",
       "       'bimodal', 'outlier', 'bimodal', 'discrete', 'normal', 'discrete',\n",
       "       'bimodal', 'normal', 'discrete', 'outlier', 'discrete', 'outlier',\n",
       "       'outlier', 'longtail', 'functional', 'discrete', 'discrete',\n",
       "       'discrete', 'bimodal', 'discrete', 'bimodal', 'outlier', 'outlier',\n",
       "       'bimodal', 'outlier', 'outlier', 'bimodal', 'outlier', 'longtail',\n",
       "       'bimodal', 'outlier', 'longtail', 'functional', 'outlier',\n",
       "       'normal', 'functional', 'outlier', 'normal', 'functional',\n",
       "       'normal', 'outlier', 'normal', 'normal', 'bimodal', 'discrete',\n",
       "       'functional', 'normal', 'functional', 'functional', 'outlier',\n",
       "       'bimodal', 'normal', 'discrete', 'functional', 'discrete',\n",
       "       'bimodal', 'outlier', 'outlier', 'normal', 'functional', 'outlier',\n",
       "       'longtail', 'discrete', 'bimodal', 'discrete', 'functional',\n",
       "       'functional', 'bimodal', 'discrete', 'outlier', 'normal',\n",
       "       'outlier', 'normal', 'outlier', 'longtail', 'longtail', 'outlier',\n",
       "       'outlier'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes = svm_classifier.predict(X_test_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "821c357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discrete' 'normal' 'outlier' 'bimodal' 'discrete' 'functional' 'bimodal'\n",
      " 'normal' 'bimodal' 'longtail' 'bimodal' 'discrete' 'discrete' 'outlier'\n",
      " 'bimodal' 'functional' 'bimodal' 'discrete' 'bimodal' 'bimodal' 'bimodal'\n",
      " 'outlier' 'outlier' 'outlier' 'normal' 'outlier' 'bimodal' 'longtail'\n",
      " 'bimodal' 'normal' 'outlier' 'discrete' 'bimodal' 'functional' 'longtail'\n",
      " 'normal' 'outlier' 'outlier' 'normal' 'functional' 'longtail' 'bimodal'\n",
      " 'bimodal' 'outlier' 'bimodal' 'discrete' 'normal' 'discrete' 'bimodal'\n",
      " 'normal' 'discrete' 'outlier' 'discrete' 'outlier' 'outlier' 'longtail'\n",
      " 'functional' 'discrete' 'discrete' 'discrete' 'bimodal' 'discrete'\n",
      " 'bimodal' 'outlier' 'outlier' 'bimodal' 'outlier' 'outlier' 'bimodal'\n",
      " 'outlier' 'longtail' 'bimodal' 'outlier' 'longtail' 'functional'\n",
      " 'outlier' 'normal' 'functional' 'outlier' 'normal' 'functional' 'normal'\n",
      " 'outlier' 'normal' 'normal' 'bimodal' 'discrete' 'functional' 'normal'\n",
      " 'functional' 'functional' 'outlier' 'bimodal' 'normal' 'discrete'\n",
      " 'functional' 'discrete' 'bimodal' 'outlier' 'outlier' 'normal'\n",
      " 'functional' 'outlier' 'longtail' 'discrete' 'bimodal' 'discrete'\n",
      " 'functional' 'functional' 'bimodal' 'discrete' 'outlier' 'normal'\n",
      " 'outlier' 'normal' 'outlier' 'longtail' 'longtail' 'outlier' 'outlier']\n",
      "120\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(pred_classes)\n",
    "print(len(pred_classes))\n",
    "print(type(pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83983721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110      discrete\n",
      "419        normal\n",
      "565       outlier\n",
      "77        bimodal\n",
      "181      discrete\n",
      "284    functional\n",
      "10        bimodal\n",
      "469        normal\n",
      "78        bimodal\n",
      "349      longtail\n",
      "55        bimodal\n",
      "118      discrete\n",
      "109      discrete\n",
      "588       outlier\n",
      "369      longtail\n",
      "234    functional\n",
      "30        bimodal\n",
      "212    functional\n",
      "184      discrete\n",
      "86        bimodal\n",
      "2         bimodal\n",
      "587       outlier\n",
      "535       outlier\n",
      "596       outlier\n",
      "368      longtail\n",
      "539       outlier\n",
      "72        bimodal\n",
      "135      discrete\n",
      "556       outlier\n",
      "437        normal\n",
      "Name: Distribution Type, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_SV[:30])\n",
    "print(type(Y_test_SV))\n",
    "print(len(Y_test_SV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1cb35d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     predicted      actual\n",
      "10     bimodal     bimodal\n",
      "11    discrete    discrete\n",
      "12    discrete    discrete\n",
      "13     outlier     outlier\n",
      "14     bimodal    longtail\n",
      "15  functional  functional\n",
      "16     bimodal     bimodal\n",
      "17    discrete  functional\n",
      "18     bimodal    discrete\n",
      "19     bimodal     bimodal\n",
      "20     bimodal     bimodal\n",
      "21     outlier     outlier\n",
      "22     outlier     outlier\n",
      "23     outlier     outlier\n",
      "24      normal    longtail\n",
      "25     outlier     outlier\n",
      "26     bimodal     bimodal\n",
      "27    longtail    discrete\n",
      "28     bimodal     outlier\n",
      "29      normal      normal\n",
      "30     outlier     outlier\n",
      "31    discrete    discrete\n",
      "32     bimodal     bimodal\n",
      "33  functional  functional\n",
      "34    longtail    discrete\n",
      "35      normal      normal\n",
      "36     outlier    discrete\n",
      "37     outlier     outlier\n",
      "38      normal      normal\n",
      "39  functional  functional\n",
      "40    longtail    longtail\n",
      "41     bimodal     bimodal\n",
      "42     bimodal     outlier\n",
      "43     outlier     outlier\n",
      "44     bimodal     bimodal\n",
      "45    discrete    discrete\n",
      "46      normal      normal\n",
      "47    discrete    discrete\n",
      "48     bimodal     bimodal\n",
      "49      normal      normal\n"
     ]
    }
   ],
   "source": [
    "compare_df = pd.DataFrame()\n",
    "compare_df['predicted'] = pred_classes\n",
    "compare_df['actual'] = np.array(Y_test_SV)\n",
    "print(compare_df[10:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4754b208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "correct_pred = sum(1 for pred,act in zip(Y_test_SV,pred_classes) if pred==act)\n",
    "print(correct_pred)\n",
    "print(correct_pred/120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d548669",
   "metadata": {},
   "source": [
    "## K-nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "650333a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "83db82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training and sorting data \n",
    "def knn(model_df):\n",
    "    #label_encoder = LabelEncoder()\n",
    "    xData = sort_df(model_df)['Data']\n",
    "    yData = sort_df(model_df)['Distribution Type']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xData,yData,test_size = 0.2,random_state=42) \n",
    "    X_train = convert_data_rows(X_train)\n",
    "    X_test = convert_data_rows(X_test)\n",
    "    X_train = np.array(X_train).astype('float64')\n",
    "    X_test= np.array(X_test).astype('float64')\n",
    "    #num_samples, num_timesteps = X_train.shape\n",
    "    #X_train = X_train.reshape(num_samples,num_timesteps,1)\n",
    "    #X_test = X_test.reshape(X_test.shape[0],num_timesteps,1)\n",
    "    #Y_train = label_encoder.fit_transform(Y_train)\n",
    "    #Y_train = to_categorical(Y_train,num_classes)\n",
    "    #Y_test = label_encoder.fit_transform(Y_test)\n",
    "    #Y_test = to_categorical(Y_test,num_classes)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2ea1fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bimodal       100\n",
      "discrete      100\n",
      "functional    100\n",
      "longtail      100\n",
      "normal        100\n",
      "outlier       100\n",
      "Name: Distribution Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trimmed_df['Distribution Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0f9e4c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "X_train_K, X_test_K, Y_train_K, Y_test_K = knn(trimmed_df)\n",
    "# Create a KNN classifier\n",
    "k = 6\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "# Fit the classifier on the training data\n",
    "knn_classifier.fit(X_train_K, Y_train_K)\n",
    "# Make predictions on the test data\n",
    "predictions = knn_classifier.predict(X_test_K)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test_K, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
