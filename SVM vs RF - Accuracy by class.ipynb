{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7b8809",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4765908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827ff72",
   "metadata": {},
   "source": [
    "### Necessary functions\n",
    "- These functions are explained in the 'data cleaning' file\n",
    "- They are necessary to format the data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95bfd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting systematic sampling (FOR FLOATS) to a function\n",
    "def float_sample_2(population,sample_size):\n",
    "    base_interval = len(population) // sample_size\n",
    "    remainder = len(population)%sample_size\n",
    "    #indices = []\n",
    "    indices = {}\n",
    "    #Add in min and max points in array\n",
    "    min_index = population.argmin()\n",
    "    max_index = population.argmax()\n",
    "    indices[0] = min_index\n",
    "    indices[1] = max_index\n",
    "    start_index = np.random.randint(0,base_interval)\n",
    "    for i in range(2,sample_size):\n",
    "        interval = base_interval + 1 if i < remainder else base_interval\n",
    "        #print(\"Interval is: \", interval)\n",
    "        index = (start_index + i * interval) % len(population)\n",
    "        #print(\"Index is: \",index)\n",
    "        #indices.append(index)\n",
    "        indices[i] = index\n",
    "    #print(\"The dict is: \",indices)\n",
    "    unique_indices = list(indices.values())\n",
    "    unique_indices = [*set(unique_indices)]\n",
    "    systematic_sample = population[unique_indices]\n",
    "    print(\"Before delete\")\n",
    "    #print(\"systematic_sample: \",systematic_sample)\n",
    "    population = np.delete(population,unique_indices)\n",
    "    print(\"After delete\")\n",
    "    if len(systematic_sample) < sample_size:\n",
    "        remaining_samples = sample_size - len(systematic_sample)\n",
    "        remaining_indices = np.random.choice(len(population),remaining_samples,replace=False)\n",
    "        systematic_sample = np.concatenate((systematic_sample,population[remaining_indices]))\n",
    "    return systematic_sample\n",
    "#Function to apply the systematic sampling for the function \n",
    "def apply_sampling(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for colName,colData in df.items():\n",
    "        data = df.dropna(subset=colName)\n",
    "        newCol = list(data[colName])\n",
    "        newCol = np.array(newCol)\n",
    "        newCol = pd.Series(float_sample_2(newCol,50000))\n",
    "        #Can only concat after sampling!!\n",
    "        new_df = pd.concat([new_df,newCol.rename(colName)],axis=1)\n",
    "    return new_df\n",
    "#Import relevant packages \n",
    "from sklearn import preprocessing\n",
    "min_max = preprocessing.MinMaxScaler()\n",
    "#Function to normalise all the columns in a dataframe\n",
    "def normalise(df):\n",
    "    final_df = pd.DataFrame()\n",
    "    for colName,colData in df.items():\n",
    "        c_scaled = min_max.fit_transform(df[[colName]])\n",
    "        c_scaled = pd.Series(c_scaled.ravel())\n",
    "        final_df = pd.concat([final_df,c_scaled.rename(colName)],axis=1)\n",
    "    return final_df\n",
    "#Function to convert all the data (individual tuple) into arrays/list for modelling\n",
    "def convert_data_rows(df):\n",
    "    data_points = []\n",
    "    for colName,colData in df.items():\n",
    "        data_points.append(np.asarray(colData))\n",
    "    return data_points\n",
    "#Function to drop columns (tests) in the raw data file which are NOT tests (i.e metadata like start time, lot number etc)\n",
    "def test_only(datafile,labelfile):\n",
    "    keys = list(labelfile['Name'])\n",
    "    df = datafile[keys]\n",
    "    return df\n",
    "def identify_col(df):\n",
    "    null_perCol = df.isnull().sum()\n",
    "    insuff_col = {}\n",
    "    for index in range(len(null_perCol)):\n",
    "        if(df.shape[0]-null_perCol[index]<50000):\n",
    "            insuff_col[null_perCol.index[index]] = null_perCol[index]\n",
    "    return list(insuff_col.keys())\n",
    "#Function to find out non applicable rows (no distribution, not part of training data)\n",
    "def non_applicable (df_label):\n",
    "    null_rowsLabel = df_label[df_label['Distribution Type'].isnull()]\n",
    "    null_rowsLabel = list(null_rowsLabel['Name'])\n",
    "    return null_rowsLabel\n",
    "def drop_col(df_dropped,less_50000):\n",
    "    pd.options.mode.chained_assignment = None \n",
    "    df = df_dropped.drop(columns=less_50000)\n",
    "    return df\n",
    "#Check if everything is replaced correctly (no more null values for the columns with <50000) data points\n",
    "def check_nonull(df):\n",
    "    null_perCol = df.isnull().sum()\n",
    "    insuff_col = {}\n",
    "    for index in range(len(null_perCol)):\n",
    "        if(df.shape[0]-null_perCol[index]<50000):\n",
    "            insuff_col[null_perCol.index[index]] = null_perCol[index]\n",
    "    print(insuff_col)\n",
    "    print(len(insuff_col))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a52bc6",
   "metadata": {},
   "source": [
    "### Importing our data \n",
    "- HK data is the data containing array instances, and they are already cleaned\n",
    "- HK label is the relabelled labels of the corresponding array instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515ca11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HK_data = pd.read_csv('HK_cleaned_EY.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b92d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HK_normalised = HK_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e706c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'UTF-16', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "filename = 'HK_labels_31_10_23.csv'\n",
    "with open(filename, 'rb') as file:\n",
    "    print(chardet.detect(file.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932c1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HK_label = pd.read_csv(r'HK_labels_31_10_23.csv',encoding = 'utf-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2b828",
   "metadata": {},
   "source": [
    "### Data cleaning and pre-preparation for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daaf64de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689\n"
     ]
    }
   ],
   "source": [
    "#Extract the corresponding columns from the label file\n",
    "good_cols = list(HK_normalised.columns)\n",
    "keys = HK_label['Name']\n",
    "extract = [i for i in keys if i in good_cols]\n",
    "print(len(extract))\n",
    "HK_corr_label = HK_label[HK_label['Name'].isin(extract)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c64a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concat the dataframes (raw data and the name of the tests) -> row format. i.e 2 columns: data, name\n",
    "def concat_xy(df):\n",
    "    cols = ['Data','Name']\n",
    "    concat_df = pd.DataFrame(columns=cols,index=range(df.shape[1]))\n",
    "    index = 0\n",
    "    for colName, colData in df.items():\n",
    "        #variable index is to retrieve the index of the columns in YK raw (final_df)\n",
    "        vals = np.array(colData.values)\n",
    "        concat_df.loc[index].Data = vals\n",
    "        concat_df.loc[index].Name = colName\n",
    "        index+=1\n",
    "    return concat_df\n",
    "#Function concatenating the Y (distribution) with the raw data (X) -> dataframe passed in is the label final! concat_df is testname_data\n",
    "def model_xy(label_df,concat_df):\n",
    "    dist_labels = label_df[['Distribution Type','Name']]\n",
    "    model_df = pd.merge(concat_df,dist_labels,on='Name')\n",
    "    #model_df_xy = model_df[['Data','Distribution Type']]\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf740f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the data beforehand before modelling\n",
    "num_classes = 6\n",
    "def sort_df(df):\n",
    "    #Make a copy then sort\n",
    "    sorted_df = df\n",
    "    for index in range(sorted_df.shape[0]):\n",
    "        sorted_df['Data'].iloc[index].sort()\n",
    "    return sorted_df\n",
    "#Function to convert all the data (individual tuple) into arrays/list for modelling\n",
    "def convert_data_rows(df):\n",
    "    data_points = []\n",
    "    for colName,colData in df.items():\n",
    "        data_points.append(np.asarray(colData))\n",
    "    return data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9022ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data  \\\n",
      "0  [0.7087378640776696, 0.737864077669903, 0.7864...   \n",
      "1  [0.4456761723727496, 0.6582697960780024, 0.557...   \n",
      "2  [0.8347090082415121, 0.6804384607235257, 0.677...   \n",
      "3  [0.0, 0.1538461538461542, 0.4615384615384617, ...   \n",
      "4  [0.6612903225806455, 0.7258064516129035, 0.709...   \n",
      "\n",
      "                                               Name  \n",
      "0  a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__  \n",
      "1   p_open_PADS.DIG.OPENVDDIO.V_x_1mA_x__SE_SPI_CLK  \n",
      "2       a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__  \n",
      "3           a_vihXvtx_CLIF.LPDET.DIFF.SEL10_x_x_x__  \n",
      "4   a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__  \n",
      "                                                Data  \\\n",
      "0  [0.7087378640776696, 0.737864077669903, 0.7864...   \n",
      "1  [0.4456761723727496, 0.6582697960780024, 0.557...   \n",
      "2  [0.8347090082415121, 0.6804384607235257, 0.677...   \n",
      "3  [0.0, 0.1538461538461542, 0.4615384615384617, ...   \n",
      "4  [0.6612903225806455, 0.7258064516129035, 0.709...   \n",
      "\n",
      "                                               Name Distribution Type  \n",
      "0  a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__           outlier  \n",
      "1   p_open_PADS.DIG.OPENVDDIO.V_x_1mA_x__SE_SPI_CLK            normal  \n",
      "2       a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__           outlier  \n",
      "3           a_vihXvtx_CLIF.LPDET.DIFF.SEL10_x_x_x__          discrete  \n",
      "4   a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__           outlier  \n",
      "outlier       809\n",
      "functional    293\n",
      "longtail      184\n",
      "normal        149\n",
      "discrete      136\n",
      "bimodal        92\n",
      "Untagged       26\n",
      "Name: Distribution Type, dtype: int64\n",
      "0          outlier\n",
      "1           normal\n",
      "2          outlier\n",
      "3         discrete\n",
      "4          outlier\n",
      "           ...    \n",
      "1684       outlier\n",
      "1685       outlier\n",
      "1686       outlier\n",
      "1687       outlier\n",
      "1688    functional\n",
      "Name: Distribution Type, Length: 1689, dtype: object\n"
     ]
    }
   ],
   "source": [
    "HK_testname_data = concat_xy(HK_normalised)\n",
    "print(HK_testname_data.head())\n",
    "HK_model = model_xy(HK_corr_label,HK_testname_data)\n",
    "print(HK_model.head())\n",
    "print(HK_model['Distribution Type'].value_counts())\n",
    "print(HK_model['Distribution Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc4bc2",
   "metadata": {},
   "source": [
    "## Modelling - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40188a54",
   "metadata": {},
   "source": [
    "### Separate them based on distribution type for separate analysis of prediction\n",
    "- This is so that we can preserve the testnames to plot them back in Exensio for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6adc78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "                                                Data  \\\n",
      "0  [0.7087378640776696, 0.737864077669903, 0.7864...   \n",
      "1  [0.4456761723727496, 0.6582697960780024, 0.557...   \n",
      "2  [0.8347090082415121, 0.6804384607235257, 0.677...   \n",
      "3  [0.0, 0.1538461538461542, 0.4615384615384617, ...   \n",
      "4  [0.6612903225806455, 0.7258064516129035, 0.709...   \n",
      "\n",
      "                                               Name Distribution Type  \n",
      "0  a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__           outlier  \n",
      "1   p_open_PADS.DIG.OPENVDDIO.V_x_1mA_x__SE_SPI_CLK            normal  \n",
      "2       a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__           outlier  \n",
      "3           a_vihXvtx_CLIF.LPDET.DIFF.SEL10_x_x_x__          discrete  \n",
      "4   a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__           outlier  \n",
      "1662\n"
     ]
    }
   ],
   "source": [
    "#Drop the tests with undeterministic distributions/not necessary for prediction\n",
    "all_tests = list(HK_model['Name'])\n",
    "#Those that are weird (to be removed) and potentially belong to another dist but are labelled to have a dist\n",
    "unecessary = ['i_TOP-MISC-DLOG_x_x_x_x__Touch-Down-Num','p_postXfreq_QA.NFC.RINGO.fe.nand2.long.0_x_nom_x','p_postXfreq_QA.NFC.RINGO.fe.nor2.long.0_x_nom_x','p_postXfreq_QA.NFC.RINGO.be.m24.rc.line_x_nom_x']\n",
    "#Remove untagged or unecessary (those that have tagged but undeterminstic)\n",
    "untagged = list(HK_model[HK_model['Distribution Type']=='Untagged']['Name'])\n",
    "print(len(untagged))\n",
    "HK_model_dropped = HK_model[~HK_model['Name'].isin(unecessary+untagged)]\n",
    "print(HK_model_dropped.head())\n",
    "print(len(HK_model_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edadcbdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outlier       809\n",
       "functional    292\n",
       "longtail      184\n",
       "normal        149\n",
       "discrete      136\n",
       "bimodal        92\n",
       "Name: Distribution Type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HK_model_dropped['Distribution Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3b700",
   "metadata": {},
   "source": [
    "### Analysing the unbalanced dataset\n",
    "- How many instances are there for each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac86a135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: bimodal\n",
      "                                                  Data  \\\n",
      "11   [0.2741480578231607, 0.2869562789139079, 0.184...   \n",
      "35   [0.3009006829558842, 0.265729385711893, 0.2835...   \n",
      "102  [0.5335934209651043, 0.2199144370802059, 0.362...   \n",
      "133  [0.0, 0.032258064516129, 1.0, 1.0, 0.032258064...   \n",
      "135  [0.0, 0.1333333333333333, 0.0, 1.0, 1.0, 0.066...   \n",
      "\n",
      "                                            Name Distribution Type  \n",
      "11         a_clk_TXDC.DELAYCHAIN_x_VDDPA.3V3_x__           bimodal  \n",
      "35       p_clc_PADS.SIG.DELTA.EOF.V_x_1mA_x__TX2           bimodal  \n",
      "102           p_short_PADS.DIG.V_x_1mA_x__PMUVCC           bimodal  \n",
      "133  ip_trim_TOP--DLOG-TRIMVALUE-VREF.LQ-WR.PFN2           bimodal  \n",
      "135  ip_trim_TOP--DLOG-TRIMVALUE-IREF.HQ-WR.PFN2           bimodal  \n",
      "------\n",
      "Group: discrete\n",
      "                                                 Data  \\\n",
      "3   [0.0, 0.1538461538461542, 0.4615384615384617, ...   \n",
      "13  [0.0, 0.7692307692307692, 0.2307692307692308, ...   \n",
      "20  [0.4000000000000001, 0.5333333333333334, 0.333...   \n",
      "37  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "40  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.3333333333333...   \n",
      "\n",
      "                                             Name Distribution Type  \n",
      "3         a_vihXvtx_CLIF.LPDET.DIFF.SEL10_x_x_x__          discrete  \n",
      "13     a_vihXvtx_CLIF.LPDET.DIFF.LOW.SEL1_x_x_x__          discrete  \n",
      "20  a_clcXrftrim_ICCal.HFO.PMUTemperature_x_x_x__          discrete  \n",
      "37            ip_nvmXutil_TOP--DLOG-W3-TESTED-DAY          discrete  \n",
      "40           a_clcXrftrim_AGCPhase.Crx.14_x_x_x__          discrete  \n",
      "------\n",
      "Group: functional\n",
      "                                                 Data  \\\n",
      "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "19  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "24  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "26  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                        Name Distribution Type  \n",
      "17                f_nvm_TOP-NVM-BISCOM.MINI2        functional  \n",
      "19            xf_bf_TOP--POWER.MODULAR-1.MNV        functional  \n",
      "24  a_clcXrftrim_CLIF.PLL.RSSI.lev13_x_x_x__        functional  \n",
      "26   a_clcXrftrim_CLIF.PLL.RSSI.lev3_x_x_x__        functional  \n",
      "27  a_clcXrftrim_CLIF.PLL.RSSI.lev18_x_x_x__        functional  \n",
      "------\n",
      "Group: longtail\n",
      "                                                 Data  \\\n",
      "9   [0.6499207530858264, 0.5641179578310336, 0.646...   \n",
      "23  [0.0262492688279037, 0.0496188249308467, 0.044...   \n",
      "46  [0.4904901176319107, 0.3722327989772758, 0.419...   \n",
      "57  [0.4994059787991223, 0.5331142882887586, 0.433...   \n",
      "67  [0.7462302836379235, 0.4883535999469854, 0.705...   \n",
      "\n",
      "                                      Name Distribution Type  \n",
      "9     p_open_PADS.DIG.EOF.V_x_1mA_x__VDDNV          longtail  \n",
      "23       a_cres_TXDC.TX2LS_x_VDDPA.3V3_x__          longtail  \n",
      "46  p_short_PADS.DIG.V_x_1mA_x__SE_ISO_CLK          longtail  \n",
      "57  p_clc_PADS.IILDELTA_x_1V8_x__NFC_GPIO0          longtail  \n",
      "67         p_short_PADS.DIG.V_x_1mA_x__RXN          longtail  \n",
      "------\n",
      "Group: normal\n",
      "                                                 Data  \\\n",
      "1   [0.4456761723727496, 0.6582697960780024, 0.557...   \n",
      "18  [0.4101262431771744, 0.4164384020359648, 0.400...   \n",
      "22  [0.4483140621754486, 0.4757783470654786, 0.263...   \n",
      "39  [0.4353422833012956, 0.5906903179912533, 0.706...   \n",
      "41  [0.4062236339272402, 0.483388753784304, 0.4725...   \n",
      "\n",
      "                                                 Name Distribution Type  \n",
      "1     p_open_PADS.DIG.OPENVDDIO.V_x_1mA_x__SE_SPI_CLK            normal  \n",
      "18          p_open_PADS.DIG.EOF.V_x_1mA_x__SE_SPI_CLK            normal  \n",
      "22            p_dcspec_PADS.VOH_x_1V8_x__NFC_GPIO3_AO            normal  \n",
      "39  a_vrf_PMUVDDPA_x_VSUP-PWR.3V6-VDDPA.3V45-0mA_x...            normal  \n",
      "41                  p_short_PADS.SIG.V_x_1mA_x__VDDPA            normal  \n",
      "------\n",
      "Group: outlier\n",
      "                                                Data  \\\n",
      "0  [0.7087378640776696, 0.737864077669903, 0.7864...   \n",
      "2  [0.8347090082415121, 0.6804384607235257, 0.677...   \n",
      "4  [0.6612903225806455, 0.7258064516129035, 0.709...   \n",
      "5  [0.952731188431121, 0.9550234828220926, 0.9497...   \n",
      "6  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "\n",
      "                                                Name Distribution Type  \n",
      "0   a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__           outlier  \n",
      "2        a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__           outlier  \n",
      "4    a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__           outlier  \n",
      "5                      a_vrf_CLIF.VCM.HP.RXN_x_x_x__           outlier  \n",
      "6  f_trustp_TOP-NFC-SE-INIT-JCOP.CASAppletID.ans2...           outlier  \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "#Grouping the dataframe by the distribution type\n",
    "grouped_df = HK_model_dropped.groupby('Distribution Type')\n",
    "#Verifying that grouping is indeed done\n",
    "for group_name, group_data in grouped_df:\n",
    "    print(\"Group: {}\".format(group_name))\n",
    "    print(group_data.head())\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93187601",
   "metadata": {},
   "source": [
    "### Trimming data to allow model to be trained with balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7991878c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Data, Name, Distribution Type]\n",
      "Index: []\n",
      "                                                  Data  \\\n",
      "0    [0.549284438224691, 0.6680452392509326, 0.3225...   \n",
      "1    [0.6203717955893876, 0.5743185925235628, 0.438...   \n",
      "2    [0.104463099767329, 0.4583138840177989, 0.3892...   \n",
      "3    [0.4847588264545095, 0.2324714072600784, 0.307...   \n",
      "4    [0.2741480578231607, 0.2869562789139079, 0.184...   \n",
      "..                                                 ...   \n",
      "535  [0.5370823145884271, 0.5215973920130399, 0.449...   \n",
      "536  [0.3209093280119366, 0.2417547091500351, 0.162...   \n",
      "537  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "538  [0.0026848040093073, 0.0035797386790764, 0.003...   \n",
      "539  [0.9999942766938472, 0.9999944533970044, 0.999...   \n",
      "\n",
      "                                                  Name Distribution Type  \n",
      "0               p_lkg_PADS.IILEND_x_1V8_x__NFC_CLK_REQ           bimodal  \n",
      "1                p_lkg_PADS.IIH_x_1V8_x__NFC_SIM_SWIO1           bimodal  \n",
      "2              p_dcspec_PADS.VOL_x_1V8_x__NFC_GPIO2_AO           bimodal  \n",
      "3               p_short_PADS.DIG.EOF.V_x_1mA_x__PMUVCC           bimodal  \n",
      "4                a_clk_TXDC.DELAYCHAIN_x_VDDPA.3V3_x__           bimodal  \n",
      "..                                                 ...               ...  \n",
      "535                a_clcXrftrim_AGCGain.Crx.61_x_x_x__           outlier  \n",
      "536                   a_vrf_XTAL.PkDet.MonAC_x_x_sig__           outlier  \n",
      "537  f_trustp_TOP-NFC-SE-INIT-JCOP.SMX.APDU.Pow.Boo...           outlier  \n",
      "538  a_vrf_PMUVDDPA.LOADREG_x_VSUP-PWR.3V65-VDDPA.3...           outlier  \n",
      "539                 a_anlXvrx_CLIF.TX_x_VDDPA.1V95_x__           outlier  \n",
      "\n",
      "[540 rows x 3 columns]\n",
      "bimodal       90\n",
      "discrete      90\n",
      "functional    90\n",
      "longtail      90\n",
      "normal        90\n",
      "outlier       90\n",
      "Name: Distribution Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Function to trim the group\n",
    "def trim_df (new_df,grouped_df):\n",
    "    trimmed_group = None\n",
    "    for _,group in grouped_df:\n",
    "        count = len(group)\n",
    "        #If the number of instance for any group is below limit (100), print warning statement\n",
    "        if count <= 90:\n",
    "            print(\"Group: {} has less than 90!\".format(group))\n",
    "        else:\n",
    "            trimmed_group = group.sample(n=90,random_state=42)\n",
    "        trimmed_df = pd.concat([new_df,trimmed_group])\n",
    "        new_df = trimmed_df\n",
    "    return trimmed_df\n",
    "#Creating a new dataframe to store the trimmed data\n",
    "trimmed_df = pd.DataFrame(columns=HK_model_dropped.columns)\n",
    "print(trimmed_df.head())\n",
    "#Applying the function\n",
    "trimmed_df = trim_df(trimmed_df,grouped_df)\n",
    "#Resetting the index of the trimmed dataframe\n",
    "trimmed_df = trimmed_df.reset_index(drop=True)\n",
    "print(trimmed_df)\n",
    "print(trimmed_df['Distribution Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24046cc7",
   "metadata": {},
   "source": [
    "### Training\n",
    "- We extracted 90 instances of each distribution\n",
    "- We trained the model with 72 instances of each distribution (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41a2409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training and sorting data \n",
    "from sklearn.model_selection import train_test_split\n",
    "def support_vector(model_df):\n",
    "    #label_encoder = LabelEncoder()\n",
    "    xData = sort_df(model_df)['Data']\n",
    "    yData = sort_df(model_df)['Distribution Type']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xData,yData,test_size = 0.2,random_state=42) \n",
    "    X_train = convert_data_rows(X_train)\n",
    "    X_test = convert_data_rows(X_test)\n",
    "    X_train = np.array(X_train).astype('float64')\n",
    "    X_test= np.array(X_test).astype('float64')\n",
    "    #num_samples, num_timesteps = X_train.shape\n",
    "    #X_train = X_train.reshape(num_samples,num_timesteps,1)\n",
    "    #X_test = X_test.reshape(X_test.shape[0],num_timesteps,1)\n",
    "    #Y_train = label_encoder.fit_transform(Y_train)\n",
    "    #Y_train = to_categorical(Y_train,num_classes)\n",
    "    #Y_test = label_encoder.fit_transform(Y_test)\n",
    "    #Y_test = to_categorical(Y_test,num_classes)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b15bd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SV, X_test_SV, Y_train_SV, Y_test_SV = support_vector(trimmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6250159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00724202 0.00724202 ... 0.94834142 0.94834142 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_SV[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f9e53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "svm_classifier = SVC(kernel='linear',random_state=42)\n",
    "svm_classifier.fit(X_train_SV,Y_train_SV)\n",
    "pred_classes = svm_classifier.predict(X_test_SV)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(pred_classes,Y_test_SV)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc5b64",
   "metadata": {},
   "source": [
    "### Extracting data based on distribution types for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2855c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "HK_model = HK_model_dropped\n",
    "outlier_df = HK_model[HK_model['Distribution Type']=='outlier']\n",
    "normal_df =  HK_model[HK_model['Distribution Type']=='normal']\n",
    "bimodal_df =  HK_model[HK_model['Distribution Type']=='bimodal']\n",
    "longtail_df =  HK_model[HK_model['Distribution Type']=='longtail']\n",
    "functional_df =  HK_model[HK_model['Distribution Type']=='functional']\n",
    "discrete_df =  HK_model[HK_model['Distribution Type']=='discrete']\n",
    "#Check if all the cases are covered\n",
    "print(len(outlier_df)+len(normal_df)+len(bimodal_df)+len(longtail_df)+len(functional_df)+len(discrete_df)==len(HK_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb64b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to conserve the test name \n",
    "def class_model(HK_model):\n",
    "    HK_arrays = sort_df(HK_model)['Data']\n",
    "    HK_arrays = convert_data_rows(HK_arrays)\n",
    "    HK_arrays = np.array(HK_arrays).astype('float64')\n",
    "    HK_testlabel = HK_model['Distribution Type']\n",
    "    return HK_arrays, HK_testlabel\n",
    "outlier_arrays, outlier_label = class_model(outlier_df)\n",
    "normal_arrays, normal_label = class_model(normal_df)\n",
    "bimodal_arrays, bimodal_label = class_model(bimodal_df)\n",
    "longtail_arrays, longtail_label = class_model(longtail_df)\n",
    "functional_arrays, functional_label = class_model(functional_df)\n",
    "discrete_arrays, discrete_label = class_model(discrete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb374f",
   "metadata": {},
   "source": [
    "### Retrieving the class accuracy for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8117e231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for outlier is: 0.9245982694684796\n",
      "Accuracy for normal is: 0.9261744966442953\n",
      "Accuracy for bimodal is: 0.8478260869565217\n",
      "Accuracy for longtail is: 0.8043478260869565\n",
      "Accuracy for functional is: 0.9315068493150684\n",
      "Accuracy for discrete is: 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "#Creating a function to test accuracy of classes \n",
    "def class_accuracy(dist,model,arrays,testlabels):\n",
    "    pred_classes = model.predict(arrays)\n",
    "    print(\"Accuracy for {} is: {}\".format(dist,accuracy_score(pred_classes,testlabels)))\n",
    "    return pred_classes\n",
    "#sv_model = svm_classifier\n",
    "outlier_pred = class_accuracy(\"outlier\",svm_classifier,outlier_arrays,outlier_label)\n",
    "normal_pred = class_accuracy(\"normal\",svm_classifier,normal_arrays,normal_label)\n",
    "bimodal_pred = class_accuracy(\"bimodal\",svm_classifier,bimodal_arrays,bimodal_label)\n",
    "longtail_pred = class_accuracy(\"longtail\",svm_classifier,longtail_arrays,longtail_label)\n",
    "functional_pred = class_accuracy(\"functional\",svm_classifier,functional_arrays,functional_label)\n",
    "discrete_pred = class_accuracy(\"discrete\",svm_classifier,discrete_arrays,discrete_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27aea2e",
   "metadata": {},
   "source": [
    "## Finding out misclassification for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94848332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier: Model predicted outlier for 748 times\n",
      "outlier: Model predicted normal for 21 times\n",
      "outlier: Model predicted longtail for 32 times\n",
      "outlier: Model predicted bimodal for 6 times\n",
      "outlier: Model predicted discrete for 2 times\n",
      "------------------------------------------------------------\n",
      "normal: Model predicted normal for 138 times\n",
      "normal: Model predicted longtail for 8 times\n",
      "normal: Model predicted bimodal for 3 times\n",
      "------------------------------------------------------------\n",
      "bimodal: Model predicted bimodal for 78 times\n",
      "bimodal: Model predicted longtail for 4 times\n",
      "bimodal: Model predicted normal for 8 times\n",
      "bimodal: Model predicted discrete for 2 times\n",
      "------------------------------------------------------------\n",
      "longtail: Model predicted longtail for 148 times\n",
      "longtail: Model predicted normal for 27 times\n",
      "longtail: Model predicted outlier for 8 times\n",
      "longtail: Model predicted discrete for 1 times\n",
      "------------------------------------------------------------\n",
      "functional: Model predicted functional for 272 times\n",
      "functional: Model predicted outlier for 4 times\n",
      "functional: Model predicted discrete for 6 times\n",
      "functional: Model predicted longtail for 3 times\n",
      "functional: Model predicted bimodal for 5 times\n",
      "functional: Model predicted normal for 2 times\n",
      "------------------------------------------------------------\n",
      "discrete: Model predicted discrete for 104 times\n",
      "discrete: Model predicted bimodal for 16 times\n",
      "discrete: Model predicted longtail for 5 times\n",
      "discrete: Model predicted normal for 11 times\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def missclass(distclass,pred_class,testlabel):\n",
    "    pred_counter = Counter(pred_class)\n",
    "    for dist, times in pred_counter.items():\n",
    "        print(\"{}: Model predicted {} for {} times\".format(distclass,dist,times))\n",
    "    print(\"------------------------------------------------------------\")\n",
    "missclass(\"outlier\",outlier_pred,outlier_label)\n",
    "missclass(\"normal\",normal_pred,normal_label)\n",
    "missclass(\"bimodal\",bimodal_pred,bimodal_label)\n",
    "missclass(\"longtail\",longtail_pred,longtail_label)\n",
    "missclass(\"functional\",functional_pred,functional_label)\n",
    "missclass(\"discrete\",discrete_pred,discrete_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8de6dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to get a predicted column\n",
    "def prediction_SVM(df,arrays,testlabels,model):\n",
    "    model_df = pd.DataFrame()\n",
    "    pred_classes = model.predict(arrays)\n",
    "    model_df['Name'] = df['Name']\n",
    "    model_df['Actual Distribution'] = testlabels\n",
    "    model_df['Predicted Distribution'] = pred_classes \n",
    "    return model_df\n",
    "#Sieve out those the specific tests that model misclassified\n",
    "def sieve_test(model_df,actual,predicted):\n",
    "    sieved = model_df[(model_df['Actual Distribution']==actual) & (model_df['Predicted Distribution']==predicted)]\n",
    "    return sieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ca04d",
   "metadata": {},
   "source": [
    "## Misclassified Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add96045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name Actual Distribution  \\\n",
      "0   a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__             outlier   \n",
      "2        a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__             outlier   \n",
      "4    a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__             outlier   \n",
      "5                      a_vrf_CLIF.VCM.HP.RXN_x_x_x__             outlier   \n",
      "6  f_trustp_TOP-NFC-SE-INIT-JCOP.CASAppletID.ans2...             outlier   \n",
      "\n",
      "  Predicted Distribution  \n",
      "0                outlier  \n",
      "2                outlier  \n",
      "4                outlier  \n",
      "5                outlier  \n",
      "6                outlier  \n"
     ]
    }
   ],
   "source": [
    "#Try for only outlier df\n",
    "outlier_predicted = prediction_SVM(outlier_df,outlier_arrays,outlier_label,svm_classifier)\n",
    "print(outlier_predicted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41e79063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Name Actual Distribution  \\\n",
      "0      a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__             outlier   \n",
      "2           a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__             outlier   \n",
      "4       a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__             outlier   \n",
      "5                         a_vrf_CLIF.VCM.HP.RXN_x_x_x__             outlier   \n",
      "6     f_trustp_TOP-NFC-SE-INIT-JCOP.CASAppletID.ans2...             outlier   \n",
      "...                                                 ...                 ...   \n",
      "1682                 p_dcspec_PADS.VOH_x_1V2_x__NFC_IRQ             outlier   \n",
      "1684  f_trustp_TOP-NFC-SE-INIT-JCOP.ConfigAppletID.a...             outlier   \n",
      "1685  f_trustp_TOP-NFC-SE-INIT-JCOP.SMX.APDU.Pow.Boo...             outlier   \n",
      "1686  a_vrf_PMUVDDPA_x_VSUP-PWR.4V25-VDDPA.3V3-530mA...             outlier   \n",
      "1687  a_icc_PMUVDDPA_x_VSUP-PWR.4V0-VDDPA.3V45.320mA...             outlier   \n",
      "\n",
      "     Predicted Distribution  \n",
      "0                   outlier  \n",
      "2                   outlier  \n",
      "4                   outlier  \n",
      "5                   outlier  \n",
      "6                   outlier  \n",
      "...                     ...  \n",
      "1682                outlier  \n",
      "1684                outlier  \n",
      "1685                outlier  \n",
      "1686                outlier  \n",
      "1687                outlier  \n",
      "\n",
      "[748 rows x 3 columns]\n",
      "(748, 3)\n"
     ]
    }
   ],
   "source": [
    "#Outliers predicted correctly as outliers\n",
    "correct = sieve_test(outlier_predicted,\"outlier\",\"outlier\")\n",
    "print(correct)\n",
    "print(correct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2dc0bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748\n",
      "21\n",
      "32\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Outliers predicted correctly as outliers\n",
    "correct = sieve_test(outlier_predicted,\"outlier\",\"outlier\")\n",
    "print(len(correct))\n",
    "correct = sieve_test(outlier_predicted,\"outlier\",\"normal\")\n",
    "print(len(correct))\n",
    "correct = sieve_test(outlier_predicted,\"outlier\",\"longtail\")\n",
    "print(len(correct))\n",
    "correct = sieve_test(outlier_predicted,\"outlier\",\"discrete\")\n",
    "print(len(correct))\n",
    "correct = sieve_test(outlier_predicted,\"outlier\",\"functional\")\n",
    "print(len(correct))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75dc71c",
   "metadata": {},
   "source": [
    "## Misclassified Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7307addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name Actual Distribution  \\\n",
      "0   a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.13_x_x_x__             outlier   \n",
      "2        a_anlXphase_CLIF.TX.BETA.40_x_VDDPA.3V3_x__             outlier   \n",
      "4    a_clcXrftrimm_CLIF.TX.PHASE.VDDPA.66C.6_x_x_x__             outlier   \n",
      "5                      a_vrf_CLIF.VCM.HP.RXN_x_x_x__             outlier   \n",
      "6  f_trustp_TOP-NFC-SE-INIT-JCOP.CASAppletID.ans2...             outlier   \n",
      "\n",
      "  Predicted Distribution  \n",
      "0                outlier  \n",
      "2                outlier  \n",
      "4                outlier  \n",
      "5                outlier  \n",
      "6                outlier  \n"
     ]
    }
   ],
   "source": [
    "#Try for only outlier df\n",
    "outlier_predicted = prediction_SVM(outlier_df,outlier_arrays,outlier_label,svm_classifier)\n",
    "print(outlier_predicted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71937d43",
   "metadata": {},
   "source": [
    "### Note - Only Normal and Outliers are shown. \n",
    "- Repeat and reuse codes to analyse other distributions accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802fae7",
   "metadata": {},
   "source": [
    "## Modelling - Random Forest\n",
    "- We then repeated the whole process of training using the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3256050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training and sorting data \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "def train_test_RF(model_df):\n",
    "    #label_encoder = LabelEncoder()\n",
    "    xData = sort_df(model_df)['Data']\n",
    "    yData = sort_df(model_df)['Distribution Type']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xData,yData,test_size = 0.2,random_state=42)\n",
    "    X_train = convert_data_rows(X_train)\n",
    "    X_test = convert_data_rows(X_test)\n",
    "    X_train = np.array(X_train).astype('float64')\n",
    "    X_test= np.array(X_test).astype('float64')\n",
    "    #num_samples, num_timesteps = X_train.shape\n",
    "    #X_train = X_train.reshape(num_samples,num_timesteps,1)\n",
    "    #X_test = X_test.reshape(X_test.shape[0],num_timesteps,1)\n",
    "    Y_train = label_encoder.fit_transform(Y_train)\n",
    "    Y_train = to_categorical(Y_train,num_classes)\n",
    "    Y_test = label_encoder.fit_transform(Y_test)\n",
    "    Y_test = to_categorical(Y_test,num_classes)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb0a3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_RF,X_test_RF,Y_train_RF,Y_test_RF = train_test_RF(trimmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e818a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier.fit(X_train_RF, Y_train_RF)\n",
    "# Predict the labels for the test set\n",
    "y_pred = rf_classifier.predict(X_test_RF)\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = np.mean(y_pred == Y_test_RF)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_pred,Y_test_RF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f075865",
   "metadata": {},
   "source": [
    "### Unpacking the encoding of Random Forest model\n",
    "- This is so that we can identify the labels as strings instead of integers and analyse them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8169a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer 0 corresponds to class labels: bimodal\n",
      "Integer 1 corresponds to class labels: discrete\n",
      "Integer 2 corresponds to class labels: functional\n",
      "Integer 3 corresponds to class labels: longtail\n",
      "Integer 4 corresponds to class labels: normal\n",
      "Integer 5 corresponds to class labels: outlier\n"
     ]
    }
   ],
   "source": [
    "class_labels = label_encoder.classes_\n",
    "labels = []\n",
    "for i,label in enumerate(class_labels):\n",
    "    print(\"Integer {} corresponds to class labels: {}\".format(i,label))\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ca59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch statements to return corresponding distributions\n",
    "def return_dist(arg):\n",
    "    match arg:\n",
    "        case 0:\n",
    "            return \"bimodal\"\n",
    "        case 1:\n",
    "            return \"discrete\"\n",
    "        case 2:\n",
    "            return \"functional\"\n",
    "        case 3:\n",
    "            return \"longtail\"\n",
    "        case 4:\n",
    "            return \"normal\"\n",
    "        case 5:\n",
    "            return \"outlier\"\n",
    "#Function to concat the distributions together\n",
    "def dist_array(num_array):\n",
    "    dist = []\n",
    "    for num in num_array:\n",
    "        dist_name = return_dist(num)\n",
    "        dist.append(dist_name)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37ebf9",
   "metadata": {},
   "source": [
    "### Retrieving the class accuracy for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9be0ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for outlier is: 0.9184177997527813\n",
      "Accuracy for normal is: 0.9664429530201343\n",
      "Accuracy for bimodal is: 0.9347826086956522\n",
      "Accuracy for longtail is: 0.8641304347826086\n",
      "Accuracy for functional is: 0.9623287671232876\n",
      "Accuracy for discrete is: 0.8455882352941176\n"
     ]
    }
   ],
   "source": [
    "#Creating a function to test accuracy of classes \n",
    "def class_accuracy_RF(dist,model,arrays,testlabels):\n",
    "    arrays = np.array(arrays).astype('float64')\n",
    "    pred_classes = model.predict(arrays)\n",
    "    pred_classes = np.argmax(pred_classes,axis=1)\n",
    "    pred_classes = dist_array(pred_classes)\n",
    "    print(\"Accuracy for {} is: {}\".format(dist,accuracy_score(pred_classes,testlabels)))\n",
    "    return pred_classes\n",
    "#sv_model = rf_classifier\n",
    "outlier_pred_RF = class_accuracy_RF(\"outlier\",rf_classifier,outlier_arrays,outlier_label)\n",
    "normal_pred_RF = class_accuracy_RF(\"normal\",rf_classifier,normal_arrays,normal_label)\n",
    "bimodal_pred_RF = class_accuracy_RF(\"bimodal\",rf_classifier,bimodal_arrays,bimodal_label)\n",
    "longtail_pred_RF = class_accuracy_RF(\"longtail\",rf_classifier,longtail_arrays,longtail_label)\n",
    "functional_pred_RF = class_accuracy_RF(\"functional\",rf_classifier,functional_arrays,functional_label)\n",
    "discrete_pred_RF = class_accuracy_RF(\"discrete\",rf_classifier,discrete_arrays,discrete_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2cd63",
   "metadata": {},
   "source": [
    "## Finding out where misclassification went wrong RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6af64fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier: Model predicted outlier for 743 times\n",
      "outlier: Model predicted normal for 10 times\n",
      "outlier: Model predicted discrete for 5 times\n",
      "outlier: Model predicted bimodal for 28 times\n",
      "outlier: Model predicted longtail for 23 times\n",
      "------------------------------------------------------------\n",
      "normal: Model predicted normal for 144 times\n",
      "normal: Model predicted bimodal for 5 times\n",
      "------------------------------------------------------------\n",
      "bimodal: Model predicted bimodal for 86 times\n",
      "bimodal: Model predicted longtail for 2 times\n",
      "bimodal: Model predicted discrete for 1 times\n",
      "bimodal: Model predicted normal for 2 times\n",
      "bimodal: Model predicted outlier for 1 times\n",
      "------------------------------------------------------------\n",
      "longtail: Model predicted longtail for 159 times\n",
      "longtail: Model predicted normal for 5 times\n",
      "longtail: Model predicted outlier for 8 times\n",
      "longtail: Model predicted bimodal for 12 times\n",
      "------------------------------------------------------------\n",
      "functional: Model predicted functional for 281 times\n",
      "functional: Model predicted outlier for 4 times\n",
      "functional: Model predicted bimodal for 7 times\n",
      "------------------------------------------------------------\n",
      "discrete: Model predicted discrete for 115 times\n",
      "discrete: Model predicted bimodal for 20 times\n",
      "discrete: Model predicted normal for 1 times\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def missclass(distclass,pred_class,testlabel):\n",
    "    pred_counter = Counter(pred_class)\n",
    "    for dist, times in pred_counter.items():\n",
    "        print(\"{}: Model predicted {} for {} times\".format(distclass,dist,times))\n",
    "    print(\"------------------------------------------------------------\")\n",
    "missclass(\"outlier\",outlier_pred_RF,outlier_label)\n",
    "missclass(\"normal\",normal_pred_RF,normal_label)\n",
    "missclass(\"bimodal\",bimodal_pred_RF,bimodal_label)\n",
    "missclass(\"longtail\",longtail_pred_RF,longtail_label)\n",
    "missclass(\"functional\",functional_pred_RF,functional_label)\n",
    "missclass(\"discrete\",discrete_pred_RF,discrete_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc0d4e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier: Model predicted outlier for 81.81818181818183 percent\n",
      "outlier: Model predicted bimodal for 9.87012987012987 percent\n",
      "outlier: Model predicted longtail for 6.363636363636363 percent\n",
      "outlier: Model predicted normal for 1.8181818181818181 percent\n",
      "outlier: Model predicted discrete for 0.12987012987012986 percent\n",
      "------------------------------------------------------------\n",
      "normal: Model predicted normal for 82.5 percent\n",
      "normal: Model predicted outlier for 2.5 percent\n",
      "normal: Model predicted bimodal for 8.333333333333332 percent\n",
      "normal: Model predicted longtail for 5.833333333333333 percent\n",
      "normal: Model predicted functional for 0.8333333333333334 percent\n",
      "------------------------------------------------------------\n",
      "bimodal: Model predicted bimodal for 100.0 percent\n",
      "------------------------------------------------------------\n",
      "longtail: Model predicted longtail for 51.55807365439094 percent\n",
      "longtail: Model predicted bimodal for 31.444759206798867 percent\n",
      "longtail: Model predicted outlier for 8.21529745042493 percent\n",
      "longtail: Model predicted normal for 8.498583569405099 percent\n",
      "longtail: Model predicted discrete for 0.28328611898017 percent\n",
      "------------------------------------------------------------\n",
      "functional: Model predicted functional for 96.69811320754717 percent\n",
      "functional: Model predicted outlier for 3.30188679245283 percent\n",
      "------------------------------------------------------------\n",
      "discrete: Model predicted discrete for 25.0 percent\n",
      "discrete: Model predicted functional for 30.0 percent\n",
      "discrete: Model predicted bimodal for 26.0 percent\n",
      "discrete: Model predicted outlier for 11.0 percent\n",
      "discrete: Model predicted normal for 5.0 percent\n",
      "discrete: Model predicted longtail for 3.0 percent\n",
      "------------------------------------------------------------\n",
      "~~~~~~~~~~~~~~~~~~~~RELABELLED MODELLLLL~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "outlier: Model predicted outlier for 91.84177997527813 percent\n",
      "outlier: Model predicted normal for 1.2360939431396787 percent\n",
      "outlier: Model predicted discrete for 0.6180469715698393 percent\n",
      "outlier: Model predicted bimodal for 3.4610630407911 percent\n",
      "outlier: Model predicted longtail for 2.843016069221261 percent\n",
      "------------------------------------------------------------\n",
      "normal: Model predicted normal for 96.64429530201343 percent\n",
      "normal: Model predicted bimodal for 3.3557046979865772 percent\n",
      "------------------------------------------------------------\n",
      "bimodal: Model predicted bimodal for 93.47826086956522 percent\n",
      "bimodal: Model predicted longtail for 2.1739130434782608 percent\n",
      "bimodal: Model predicted discrete for 1.0869565217391304 percent\n",
      "bimodal: Model predicted normal for 2.1739130434782608 percent\n",
      "bimodal: Model predicted outlier for 1.0869565217391304 percent\n",
      "------------------------------------------------------------\n",
      "longtail: Model predicted longtail for 86.41304347826086 percent\n",
      "longtail: Model predicted normal for 2.717391304347826 percent\n",
      "longtail: Model predicted outlier for 4.3478260869565215 percent\n",
      "longtail: Model predicted bimodal for 6.521739130434782 percent\n",
      "------------------------------------------------------------\n",
      "functional: Model predicted functional for 96.23287671232876 percent\n",
      "functional: Model predicted outlier for 1.36986301369863 percent\n",
      "functional: Model predicted bimodal for 2.3972602739726026 percent\n",
      "------------------------------------------------------------\n",
      "discrete: Model predicted discrete for 84.55882352941177 percent\n",
      "discrete: Model predicted bimodal for 14.705882352941178 percent\n",
      "discrete: Model predicted normal for 0.7352941176470588 percent\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Accuracy in proportion\n",
    "from collections import Counter\n",
    "def missclass_prop(distclass,pred_class,testlabel):\n",
    "    pred_counter = Counter(pred_class)\n",
    "    for dist, times in pred_counter.items():\n",
    "        print(\"{}: Model predicted {} for {} percent\".format(distclass,dist, (times/len(testlabel)*100) ))\n",
    "    print(\"------------------------------------------------------------\")\n",
    "#For old\n",
    "'''\n",
    "missclass_prop(\"outlier\",outlier_pred_RF_old,outlier_label_old)\n",
    "missclass_prop(\"normal\",normal_pred_RF_old,normal_label_old)\n",
    "missclass_prop(\"bimodal\",bimodal_pred_RF_old,bimodal_label_old)\n",
    "missclass_prop(\"longtail\",longtail_pred_RF_old,longtail_label_old)\n",
    "missclass_prop(\"functional\",functional_pred_RF_old,functional_label_old)\n",
    "missclass_prop(\"discrete\",discrete_pred_RF_old,discrete_label_old)\n",
    "'''\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~RELABELLED MODELLLLL~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "#For new\n",
    "missclass_prop(\"outlier\",outlier_pred_RF,outlier_label)\n",
    "missclass_prop(\"normal\",normal_pred_RF,normal_label)\n",
    "missclass_prop(\"bimodal\",bimodal_pred_RF,bimodal_label)\n",
    "missclass_prop(\"longtail\",longtail_pred_RF,longtail_label)\n",
    "missclass_prop(\"functional\",functional_pred_RF,functional_label)\n",
    "missclass_prop(\"discrete\",discrete_pred_RF,discrete_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a4040",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "- Random Forests and Support Vector Machine both perform relatively well >75%\n",
    "- Random Forests predicts best in: 1. Normal, 2. Functional, 3. Bimodal\n",
    "- Support Vector Machine predicts best in: 1. Functional, 2. Normal, 3. Outlier\n",
    "- We can exploit these data for future steps (for further explanation, refer to 'Ensemble Learning Attempt' pdf report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
